[{"content":"Introduction This is an Asynchronous Job Queue system that relies on NATS JetStream for storage and general job life cycle management. It is compatible with any NATS JetStream based system like a private hosted JetStream, Choria Streams or a commercial SaaS.\nEach Task is stored in JetStream by a unique ID and Work Queue item is made referencing that Task. JetStream will handle dealing with scheduling, retries, acknowledgements and more of the Work Queue item. The stored Task will be updated during the lifecycle.\nMultiple processes can process jobs concurrently, thus job processing is both horizontally and vertically scalable. Job handlers are implemented in Go with one process hosting one or many handlers. Other languages can implement Job Handlers using NATS Request-Reply services. Per process concurrency and overall per-queue concurrency controls exist.\nSynopsis Tasks are published to Work Queues:\n// establish a connection to the EMAIL work queue using a NATS context client, _ := asyncjobs.NewClient(asyncjobs.NatsConn(nc), asyncjobs.BindWorkQueue(\"EMAIL\"))  // create a task with the type 'email:new' and body from newEmail() task, _ := asyncjobs.NewTask(\"email:new\", newEmail())  // store it in the Work Queue client.EnqueueTask(ctx, task) Tasks are processes by horizontally and vertically scalable processes. Typically, a Handler handles one type of Task. We have Prometheus integration, concurrency and backoffs configured.\n// establish a connection to the EMAIL work queue using a // NATS context, with concurrency, prometheus stats and backoff client, _ := asyncjobs.NewClient( \tasyncjobs.NatsContext(\"EMAIL\"), \tasyncjobs.BindWorkQueue(\"EMAIL\"), \tasyncjobs.ClientConcurrency(10), \tasyncjobs.PrometheusListenPort(8080), \tasyncjobs.RetryBackoffPolicy(asyncjobs.RetryLinearTenMinutes))  router := asyncjobs.NewTaskRouter() router.Handler(\"email:new\", func(ctx context.Context, log asyncjobs.Logger, task *asyncjobs.Task) (any, error) { \tlog.Printf(\"Processing task %s\", task.ID)  \t// do work here using task.Payload  \treturn \"sent\", nil })  client.Run(ctx, router) ","description":"","tags":null,"title":"Choria Async Jobs","uri":"/"},{"content":"This is a basic walkthrough of publishing Tasks and handling Tasks in Go. A more thorough guide will be written in time.\nThis is an introductory guide, we have extensive Go reference documentation.\nThis guide is known to work with Release 0.0.4\nConnecting to JetStream A connection to a JetStream server is needed, you can either prepare a connecting yourself or pass in the name of a NATS Context\nNATS have a plethora of connection methods, security approaches, TLS or non TLS and even supports Websockets - you can configure it any way you wish. See the nats.go package for details.\nFirst an example passing in a already prepared nats connection:\nnc, err := nats.Connect(\"localhost:4222\") panicIfErr(err)  client, err := asyncjobs.NewClient(asyncjobs.NatsConn(nc)) panicIfErr(err) Or if you have a NATS Context called AJC you can use it:\nclient, err := asyncjobs.NewClient(asyncjobs.NatsContext(\"AJC\")) panicIfErr(err) In both cases a number of options can be supplied to log disconnections, reconnections and more.\nConfiguring Queues A Queue is where messages go, you can have many different, named, queues if you wish. If you do not specify any Queue a default one is made called DEFAULT.\nYou might make different Queues to set different concurrency limits, different max attempts, maximum validity and more.\nqueue := \u0026asyncjobs.Queue{Name: \"EMAIL\", MaxRunTime: 60 * time.Minute, MaxTries: 50}  client, err := asyncjobs.NewClient(asyncjobs.NatsContext(\"EMAIL\"), asyncjobs.WorkQueue(queue)) panicIfErr(err) Here we attach to or create a new queue called EMAIL setting some specific options. If the queue already exist we will just attach but not update configuration. You can prevent on-demand creation by setting NoCreate: true. See go doc for details.\nCreating and Enqueueing Tasks A task can be anything you wish as long as it can serialize to JSON. Tasks have types like email:new, email-new or really anything you want, we’ll see later how task types interact with the routing system.\nAny number of producers can create tasks from any number of different processes.\nFirst we have a simplistic helper to create a map that describes an email:\nfunc newEmail(to, subject, body string) any {  return map[string]string{\"to\": to, \"subject\": subject, \"body\": body} } Now we can create a new email task and enqueue it:\nclient, err := asyncjobs.NewClient(  asyncjobs.NatsContext(\"EMAIL\"),  asyncjobs.WorkQueue(\u0026asyncjobs.Queue{Name: \"EMAIL\", NoCreate: true})) panicIfErr(err)  email := newEmail(\"user@example.net\", \"Test Subject\", \"Test Body\")  task, err := asyncjobs.NewTask(\"email:new\", email) panicIfErr(err)  err = client.EnqueueTask(context.Background(), task) panicIfErr(err) The task is sent to the store and placed in the EMAIL work queue for processing.\nConsuming and Processing Tasks Messages are consumed and handled by matching their type and from a specific Queue. Task processors can run concurrently across different processes and each processes can process a number of tasks concurrently. Per-process and per-Queue concurrency limits can be set.\nWe’ll show a few more options than typical to get a feel for what’s possible.\nclient, err := asyncjobs.NewClient(  asyncjobs.NatsContext(\"EMAIL\"),  // 10 Tasks handled by this process concurrently  asyncjobs.ClientConcurrency(10),  // Prometheus stats on 0.0.0.0:8080/metrics  asyncjobs.PrometheusListenPort(8080),  // Logs using an already-prepared logger  asyncjobs.CustomLogger(log),  // Schedules retries on a jittering backoff between 1 and 10 minutes  asyncjobs.RetryBackoffPolicy(asyncjobs.RetryLinearTenMinutes),  // Connects to a queue that should already exist  asyncjobs.BindWorkQueue(\"EMAIL\")) panicIfErr(err)  router := asyncjobs.NewTaskRouter() err = router.Handler(\"email:new\", func(ctx context.Context, log asyncjobs.Logger, task *asyncjobs.Task) (any, error) {  log.Printf(\"Processing task %s\", task.ID)   // do work here using task.Payload   return \"sent\", nil }) panicIfErr(err)  err = client.Run(ctx, routeR) panicIfErr(err) Here we registered one handler for email:new and a callback that will handle that task up to 10 at a time.\nLoading a task Existing tasks can be loaded which will include their status and other details:\nclient, err := asyncjobs.NewClient(asyncjobs.NatsContext(\"EMAIL\")) panicIfErr(err)  task, err := client.LoadTaskByID(\"24Y0rDk7kMHYHKwMSCxQZOocLH3\") panicIfErr(err) ","description":"","tags":null,"title":"Golang Walkthrough","uri":"/overview/golang-overview/"},{"content":"A task is the basic item of work that is scheduled and processed by a Handler.\nTask Storage Tasks are stored in NATS JetStream in a Stream called CHORIA_AJ_TASKS. Every Task is stored in a subject keyed by it’s ID CHORIA_AJ.T.\u003cTASK ID\u003e. Tasks must have unique IDs.\nTask storage defaults to being File based and non replicated with no limits on the number of Tasks or how long they are retained. It’s recommended that an appropriate retention time is set as detailed below.\nOn a new setup the Task storage can be initialized with different defaults:\n$ ajc tasks initialize --retention 1h --memory --replicas 1 Tasks Storage: Entries: 0 @ 0 B Memory Based: true Replicas: 1 Archive Period: 1h0m0s In code this can be done first time a client starts:\nclient, err := asyncjobs.NewClient(  asyncjobs.NatsContext(\"AJC\"),  asyncjobs.MemoryStorage(),  asyncjobs.StoreReplicas(1),  asyncjobs.TaskRetention(time.Hour)) Once created the Retention period can be adjusted:\n$ ajc tasks configure 5h Tasks Storage: Entries: 0 @ 0 B Memory Based: true Replicas: 1 Archive Period: 5h0m0s Task Properties Tasks have a number of properties that can influence their processing:\n   Property Description     Type A string like email:new, the task router would dispatch the Taek to any Handler like email:new, email or ``   Payload The content of the task which the handler can read to influence what it does   Deadline Before calling the Handler the Task Deadline will be checked, tasks past their Deadlne will not be processed   MaxTries Tasks that have already had this many tries will be terminated, defaults to 10 since 0.0.8   Dependencies Task IDs that should all complete successfully before this task will run, since 0.0.8   LoadDependencies For tasks with Dependencies, load dependency TaskResults into DependencyResults before calling a handler, since 0.0.8    Setting other properties on new Tasks should be avoided.\nTask Outcomes During the lifecycle of a task various properties will be set, State is the main one that can be updated many times as per the below section, others will also be set though:\n   Property Description     Queue Once enqueued this will be the Queue name it is stored in   Result On success this structure will be set with the time of completion and the result payload   State As in the section below   CreatedAt A time-stamp indicating when the task was firt enqueued   LastTriedAt When not nil, this is the last time-stamp a handler was called   Tries Is how many times the task have been sent to Handlers   LastErr When not empty this is the text of the most recent error from the Handler    Task States Tasks have many possible states and the processor will update the task as it traverses the various states.\n   State Description     TaskStateUnknown No state is set in the task, uninitialised or corrupt task   TaskStateNew A brand new task, either never processed or possibly not enqueued   TaskStateActive A task that is being handled by a handler   TaskStateRetry A task that had a previous failure and is now scheduled for later retry or one that was manually retried   TaskStateExpired A task that was attempted to be processed but at that time it exceeded its deadline   TaskStateTerminated A handler returned an ErrTerminateTask error and so will not be retried again   TaskStateCompleted Successful completed task   TaskStateQueueError Task was created but the Work Queue entry could not be made   TaskStateBlocked When a Task is waiting on it’s dependencies (since 0.0.8)   TaskStateUnreachable When a Task cannot execute because a dependent task failed (since 0.0.8)    Some termination states like when a Queue is configured to only keep Tasks for 5 Hours but a task has had no processor for that entire period will not be reflected in the task state - the task will simply be orphaned.\nTask Dependencies Since 0.0.8 we support a notion of task dependencies. A task with dependencies will start in TaskStateBlocked, when they is scheduled the processor will check all dependencies, if all are complete the task will become Active.\nShould one of the dependent tasks have a final failure state this task will become TaskStateUnreachable as a final state.\nRetrying a Task While a Task is still in the Task Store and if it’s ID is known it can be retried. Any Work Queue items for the disk will be discarded, the task will be set to TaskStateRetry, it’s Result will be discarded and it will be enqueued again for processing.\nerr = client.RetryTaskByID(ctx, \"24atXzUomFeTt4OK4yNJNafNQR3\") The CLI can also retry tasks using ajc task retry 24atXzUomFeTt4OK4yNJNafNQR3.\nEnd State Discard With no additional actions Tasks are kept either forever or, as above, based on Task Store retention policy.\nThe client can be configured to discard certain Tasks though:\nclient, _ := ayncjobs.NewClient(  ayncjobs.NatsConn(nc),  DiscardTaskStates(TaskStateExpired, TaskStateCompleted)) Here we configure the client that whenever it sets a task to either TaskStateExpired or TaskStateCompleted it should save the state and then discard the Task.\nThe Task is first saved to allow any processes watching task life cycles to get notified. This behavior will change once #15 is completed.\nFlow Diagram This includes the Task Relationships introduced in 0.0.8\n\n","description":"","tags":null,"title":"Tasks lifecycle","uri":"/reference/task-lifecycle/"},{"content":"This is a basic walkthrough of publishing Tasks and handling them using the CLI.\nThis is essentially the CLI version of Introductory Golang Walkthrough.\nThis guide is known to work with Release 0.0.4\nWe have a similar video walkthrough that discuss the CLI and related topics.\nRequirements You’ll need the NATS CLI, an optional JetStream Server and the Async Jobs CLI,\n$ go install github.com/choria-io/asyncjobs/ajc@v0.0.4 JetStream If you have an existing JetStream server add a context to connect to it:\n$ nats context add AJC --server jetstream.example.net:4222 If you do not yet have JetStream you can start a local development copy easily, it will create a AJC context for you:\n$ nats server run --jetstream AJC ... [21398] [INF] Starting JetStream [21398] [INF] _ ___ _____ ___ _____ ___ ___ _ __ __ [21398] [INF] _ | | __|_ _/ __|_ _| _ \\ __| /_\\ | \\/ | [21398] [INF] | || | _| | | \\__ \\ | | | / _| / _ \\| |\\/| | [21398] [INF] \\__/|___| |_| |___/ |_| |_|_\\___/_/ \\_\\_| |_| [21398] [INF] [21398] [INF] https://docs.nats.io/jetstream [21398] [INF] [21398] [INF] ---------------- JETSTREAM ---------------- [21398] [INF] Max Memory: 7.20 GB [21398] [INF] Max Storage: 6.85 GB [21398] [INF] Store Directory: \"/home/rip/.local/share/nats/AJC/jetstream\" [21398] [INF] ------------------------------------------- [21398] [INF] Listening for client connections on 0.0.0.0:45913 [21398] [INF] Server is ready Creating Queues A Queue is where messages go, you can have many different, named, queues if you wish. If you do not specify any Queue a default one is made called DEFAULT.\nYou might make different Queues to set different concurrency limits, different max attempts, maximum validity and more.\n$ ajc queue add EMAIL --run-time 1h --tries 50 EMAIL Work Queue: Entries: 0 @ 0 B Memory Based: false Replicas: 1 Archive Period: forever Max Task Tries: 50 Max Run Time: 1h0m0s Max Concurrent: 100 Max Entries: unlimited Here we attach to or create a new queue called EMAIL setting some specific options.\nCreating and Enqueueing Tasks A task can be anything you wish as long as it can serialize to JSON. Tasks have types like email:new, email-new or really anything you want, we’ll see later how task types interact with the routing system.\nAny number of producers can create tasks from any number of different processes.\n$ ajc task add --queue EMAIL email:new '{\"to\":\"user@example.net\", \"subject\":\"Test Subject\", \"body\":\"Test Body\"}' Enqueued task 24YUZF4MzOCLgI7kpwrGtT4lYnS $ ajc task view 24YUZF4MzOCLgI7kpwrGtT4lYnS Task 24YUZF4MzOCLgI7kpwrGtT4lYnS created at 02 Feb 22 13:04:26 UTC Payload: 85 B Status: new Queue: EMAIL Tries: 0 Consuming and Processing Tasks The CLI can process tasks through a shell command, lets create a basic command\n$ touch /tmp/send-email.sh $ vi /tmp/send-email.sh $ chmod a+x /tmp/send-email.sh #!/bin/bash  echo '{\"status\":\"success\"}' Now lets run the jobs in our EMAIL queue, 5 concurrently:\n$ ajc task process \"\" EMAIL 5 /tmp/send-email.sh --monitor 8080 WARN[0000] Exposing Prometheus metrics on port 8080 INFO[0000] Running task 24YUZF4MzOCLgI7kpwrGtT4lYnS try 1 INFO[0000] Task 24YUZF4MzOCLgI7kpwrGtT4lYnS completed after 2.425439ms and 1 tries with 18 B payload This will process all tasks - \"\" task type - via /tmp/send-email.sh. You can curl to http://localhost:8080/metrics to see Prometheus stats.\nAfterward your task will be shown as done:\n$ ajc task view 24YUZF4MzOCLgI7kpwrGtT4lYnS Task 24YUZF4MzOCLgI7kpwrGtT4lYnS created at 02 Feb 22 13:04:26 UTC Payload: 85 B Status: complete Completed: 02 Feb 22 13:07:09 UTC (2m42s) Queue: EMAIL Tries: 1 Watching Tasks Processing You can view tasks processing through their life cycle using the CLI:\n$ ajc task watch [14:08:41] 24YUZF4MzOCLgI7kpwrGtT4lYnS: queue: EMAIL type: email:new tries: 0 state: new [13:08:41] 24YUZF4MzOCLgI7kpwrGtT4lYnS: queue: EMAIL type: email:new tries: 0 state: active [13:08:41] 24YUZF4MzOCLgI7kpwrGtT4lYnS: queue: EMAIL type: email:new tries: 1 state: complete Listing Queues and Tasks You can see all your queues with some basic statusses:\n$ ajc queue ls ╭─────────────────────────────────────────────────────────────────────────────╮ │ Work Queues │ ├─────────┬───────┬───────┬──────────┬───────────┬───────────┬────────────────┤ │ Name │ Items │ Size │ Replicas │ Max Tries │ Max Items │ Max Concurrent │ ├─────────┼───────┼───────┼──────────┼───────────┼───────────┼────────────────┤ │ EMAIL │ 0 │ 0 B │ 1 │ 50 │ unlimited │ 100 │ │ DEFAULT │ 3 │ 489 B │ 1 │ 100 │ unlimited │ 100 │ ╰─────────┴───────┴───────┴──────────┴───────────┴───────────┴────────────────╯ You can see tasks and their statusses:\n$ ajc task ls ╭───────────────────────────────────────────────────────────────────────────────────────────────╮ │ 2 Tasks │ ├─────────────────────────────┬───────────┬────────────────────────┬──────────┬─────────┬───────┤ │ ID │ Type │ Created │ State │ Queue │ Tries │ ├─────────────────────────────┼───────────┼────────────────────────┼──────────┼─────────┼───────┤ │ 24YUZF4MzOCLgI7kpwrGtT4lYnS │ email:new │ 02 Feb 22 13:04:26 UTC │ complete │ EMAIL │ 1 │ │ 24YV5AyE6epR8XMpIdIzcppYyBK │ email:new │ 02 Feb 22 13:08:41 UTC │ complete │ EMAIL │ 1 │ ╰─────────────────────────────┴───────────┴────────────────────────┴──────────┴─────────┴───────╯ And a general overview:\n$ ajc info Tasks Storage: Entries: 5 @ 2.2 KiB Memory Based: false Replicas: 1 Archive Period: forever First Entry: 02 Feb 22 13:01:19 UTC (14m24s) Last Update: 02 Feb 22 13:08:41 UTC (7m2s) DEFAULT Work Queue: Entries: 3 @ 489 B Memory Based: false Replicas: 1 Archive Period: forever Max Task Tries: 100 Max Run Time: 1m0s Max Concurrent: 100 Max Entries: unlimited First Item: 02 Feb 22 13:01:19 UTC (14m24s) Last Item: 02 Feb 22 13:02:16 UTC (13m27s) EMAIL Work Queue: Entries: 0 @ 0 B Memory Based: false Replicas: 1 Archive Period: forever Max Task Tries: 50 Max Run Time: 1h0m0s Max Concurrent: 100 Max Entries: unlimited Last Item: 02 Feb 22 13:08:41 UTC (7m2s) ","description":"","tags":null,"title":"CLI Walkthrough","uri":"/overview/cli-overview/"},{"content":"Processing Tasks is what it’s all about, so, this is an important topic to explore and understand. It is quite simple in the general case but there are some nuances to be aware of.\nHandlers are how Tasks get executed, typically this is code you provide written in Go.\nFor a non Go solution see Remote Request Reply Handlers, but reading this page is still good for a grounding understanding since remote Handlers map exactly onto the same concepts.\nExample Below is a handler that sends an email, the task Payload is a serialized object describing an email to send. The deadlines and timeouts are extracted from the Context and the mail is sent.\nThe Task handler then is a single-purpose piece of code capable of handling 1 type of Task.\nfunc emailNewHandler(ctx context.Context, log asycjobs.Logger, task *asyncjobs.Task) (any, error) { \t// Parse the task payload into an email \temail, err := parseEmail(task.Payload) \tif err != nil { return nil, err }  \t// extract the deadline from the context \tdeadline, ok := ctx.Deadline() \tif !ok { deadline = time.Now().Add(time.Minute) }  \t// send the email using github.com/xhit/go-simple-mail \tserver := mail.NewSMTPClient()  server.Host = \"smtp.example.com\" \tserver.Port = 587 \tserver.ConnectTimeout = 2 * time.Second \tserver.SendTimeout = time.Until(deadline) \t\tclient, err := server.Connect() \tif err != nil { return nil, err }  \tclient.SetFrom(EmailFrom).AddTo(email.To).SetSubject(email.Subject).SetBody(mail.TextHTML, email.Body) \terr = email.Send(client) \tif err != nil { return nil, err }  \tlog.Infof(\"Sent an email to %s\", email.To)   return \"success\", nil } Routing Tasks to Handlers Every client that processes messages must be ready to process all messages found in the Queue. So if you have an EMAIL queue, all running clients must be able to handle all Tasks.\nShould there be no appropriate handler the message will fail and enter retries.\nTask delivery is handled by asyncjobs.Mux which today is quite minimal, we plan to support Middleware and more later.\nrouter := asyncjobs.NewTaskRouter() router.HandleFunc(\"email:new\", emailNewHandler) router.HandleFunc(\"\", emailPassthroughHandler)  client.Run(ctx, router) Here we set up the above example handler to handle email:new messages and register an handler for other messages. A handler could be set to handle email: messages and it would process all unhandled email related messages.\nConcurrency There are 2 kinds of Concurrency control in effect at any time: Client and Queue.\nClient Concurrency Every client can limit how many concurrent tasks it wish to handle. You might have 4 cores in your instance and so want to run only 4 Handlers at a time.\nclient, err := asyncjobs.NewClient(asyncjobs.ClientConcurrency(runtime.NumCPU())) Here we set the client to use runtime.NumCPU() to dynamically allocate maximum concurrency based on available logical CPUs.\nQueue Concurrency When many clients are active against a specific Queue they would all get jobs according to the limit above. You might also want to limit the overall concurrency of all email processing regardless of how many clients you have. With 10 clients each set to allow 10 concurrent you would be handling 100 tasks, but if you know your infrastructure can only support 50 at a time you can limit this on the Queue.\nqueue := \u0026asyncjobs.Queue{ \tName: \"EMAIL\", \tMaxConcurrent: 50 } client, err := asyncjobs.NewClient(asyncjobs.WorkQueue(queue)) This would create a new Queue the first time and set it to 50 maximum concurrent handlers - regardless of how many your clients start.\nYou can adjust this once created using ajc queue configure EMAIL --concurrent 100.\nTask Runtime and Max Tries The Queue defines how long a Task can be processed, a Task that is not done being processed by that timeout will result in a retry - on the assumption that the handler has crashed. You should set the timeout carefully to avoid duplicate task handling.\nqueue := \u0026asyncjobs.Queue{ \tName: \"EMAIL\", \tMaxRunTime: time.Hour, \tMaxTries: 100, } Above we define a Queue that will allow a task to be handled for up to 1 hour and will retry it 100 times. Care should be taken to pick these values correctly.\nThe ajc command line utility can adjust these times post-creation but running clients will still create context Deadlines based on the configuration that was set when they were started.\nTerminating Processing In the earlier example we had these 2 lines:\nemail, err := parseEmail(task.Payload) if err != nil { return nil, err } This would return the parse error from your Handler, the task would then go and get retried later. Thing is if this is a bad Payload it will never pass processing, invalid JSON will always be invalid JSON. You might want to give up on the task early:\nemail, err := parseEmail(task.Payload) if err != nil { \treturn nil, fmt.Errorf(\"invalid task payload: %w\", asyncjobs.ErrTerminateTask) } Here we return an error that is a asyncjobs.ErrTerminateTask, the task would then be terminated immediately, no future tries will be done and the task state will be set to TaskStateTerminated.\nRetry Schedules When a client determines that a Task has failed and needs to be retried it does so based on a RetryPolicy. The default policy is to retry at increasing intervals between 1 minute and 10 minutes with a jitter applied.\nTo change to a 50 step policy ranging between 10 minutes and 1 hour use:\nclient, err := asyncjobs.NewClient(RetryBackoffPolicy(asyncjobs.RetryLinearOneHour)) We have RetryLinearTenMinutes, RetryLinearOneHour and RetryLinearOneMinute pre-defined.\nYou can create your own schedule - perhaps based on an exponential backoff - by filling in your values in asyncjobs.RetryPolicy or by implementing the asyncjobs.RetryPolicyProvider interface.\n","description":"","tags":null,"title":"Routing, Concurrency, Retry","uri":"/reference/routing-concurrency-retry/"},{"content":"The Task Scheduler allows you to create cron like entries that will create Tasks on demand.\nThis requires a separate process to be run that will supervise the configured schedules and create the tasks. We have such a Scheduler built into the ajc binary deployable in any container manager.\nThe scheduler we provide support being deployed in a highly-available cluster, they will perform leader election with one of the cluster scheduling tasks. There is no need to restart or signal these schedulers as tasks are added, removed or updated.\nYou can Deploy to Kubernetes using our Helm Charts, or run anywhere else as per below guide.\nSchedule Overview A Scheduled task takes a Cron like Schedule and some Task related properties and will then create new jobs on demand using those properties as templates.\n// ScheduledTask represents a cron like schedule and task properties that will // result in regular new tasks to be created machine schedule type ScheduledTask struct { \t// Name is a unique name for the scheduled task \tName string `json:\"name\"` \t// Schedule is a cron specification for the schedule \tSchedule string `json:\"schedule\"` \t// Queue is the name of a queue to enqueue the task into \tQueue string `json:\"queue\"` \t// TaskType is the type of task to create \tTaskType string `json:\"task_type\"` \t// Payload is the task payload for the enqueued tasks \tPayload []byte `json:\"payload\"` \t// Deadline is the time after scheduling that the deadline would be \tDeadline time.Duration `json:\"deadline,omitempty\"` \t// MaxTries is how many times the created task could be tried \tMaxTries int `json:\"max_tries\"` \t// CreatedAt is when the schedule was created \tCreatedAt time.Time `json:\"created_at\"` } Valid schedules are like those for the common unix utility cron, including the syntaxes like */5 and so forth. Short cuts for @yearly, @monthly, @weekly, @daily and @hourly are supported in addition to @every 10m where 10m is a Go standard duration.\nGo API Adding and loading Scheduled Tasks is a lot like a normal task:\nclient, _ := aj.NewClient(asyncjobs.NatsContext(\"AJC\"))  // The deadline being an hour from now will result in a Schedule Task with a 1 hour deadline set task, _ := aj.NewTask(\"email:monthly\", nil, aj.TaskDeadlin(time.Now().Add(time.Hour)))  // Create the schedule err := client.NewScheduledTask(\"EMAIL_MONTHLY_UPDATE\", \"@monthly\", \"EMAIL\", task)  // Load it st, _ := client.LoadScheduledTaskByName(\"EMAIL_MONTHLY_UPDATE\")  // Remove it err = client.RemoveScheduledTask(\"EMAIL_MONTHLY_UPDATE\") CLI management Below a quick overview of the CLI, the CLI is brand new so some aspects might change.\nAdding and Removing Scheduled Tasks $ ajc task cron add EMAIL_MONTHLY_UPDATE \"0 0 1 * *\" email:monthly --queue EMAIL --deadline 12h Scheduled Task EMAIL_MONTHLY_UPDATE created at 17 Feb 22 17:40:37 UTC Schedule: 0 0 1 * * Queue: EMAIL Task Type: email:monthly Payload: 0 B Scheduling Deadline: 12h0m0s We add a scheduled task that will run monthly (Could also use monthly instead of cron format), it will create a task with type email:monthly in the EMAIL queue and we set a deadline on the task 12 hours after creation.\nTo enter the schedule @yearly use just “yearly” as the CLI package will interpret the @.\nGiven the name, you can remove it again with ajc task cron delete EMAIL_MONTHLY_UPDATE, it supports -f for non interactive.\nViewing schedules A list of schedules can be loaded:\n$ ajc task cron list ╭───────────────────────────────────────────────────────────────────────────────────╮ │ 1 Scheduled Task(s) │ ├──────────────────────┬───────────┬───────┬───────────────┬────────────────────────┤ │ Name │ Schedule │ Queue │ Task Type │ Created │ ├──────────────────────┼───────────┼───────┼───────────────┼────────────────────────┤ │ EMAIL_MONTHLY_UPDATE │ 0 0 1 * * │ EMAIL │ email:monthly │ 17 Feb 22 17:40:37 UTC │ ╰──────────────────────┴───────────┴───────┴───────────────┴────────────────────────╯ $ ajc task cron list --names EMAIL_MONTHLY_UPDATE A single schedule can be viewed:\n$ ajc task cron view EMAIL_MONTHLY_UPDATE Scheduled Task EMAIL_MONTHLY_UPDATE created at 17 Feb 22 17:40:37 UTC Schedule: 0 0 1 * * Queue: EMAIL Task Type: email:monthly Payload: 0 B Scheduling Deadline: 12h0m0s $ ajc task cron viww EMAIL_MONTHLY_UPDATE --json { \"name\": \"EMAIL_MONTHLY_UPDATE\", \"schedule\": \"0 0 1 * *\", \"queue\": \"EMAIL\", \"task_type\": \"email:monthly\", \"payload\": null, \"Deadline\": 43200000000000, \"MaxTries\": 0, \"created_at\": \"2022-02-17T17:40:37.001480991Z\" } Running the Scheduler You can Deploy to Kubernetes using our Helm Charts, or run anywhere else as per below guide.\nEach scheduler needs an, ideally unique, name. This will be used in some logs and in leader elections.\n$ ajc task cron scheduler $(hostname -f) --monitor 8080 --context AJC INFO[19:21:29] Starting leader election as dev1.example.net INFO[19:21:29] Registered a new item EMAIL_MONTHLY_UPDATE on queue EMAIL: 0 0 1 * * INFO[19:21:29] Loaded 1 scheduled task(s) INFO[19:21:42] Became leader, tasks will be scheduled As Scheduled jobs are added or removed logs will be logged and updates about scheduling tasks will be shown. Prometheus metrics is on port 8080 in /metrics.\nYou can run as many schedulers as you want, they will do leader elections, all will log Schedule updates but only one will create Tasks. NOTE there’s a chance that during a leadership change some tasks will not be scheduled, this is something we will resolve later.\nWhen running ajc info will have some details:\n$ ajc info ... Leader Elections: Entries: 1 @ 139 B Memory Based: false Replicas: 1 Elections: task_scheduler: dev1.example.net ... Here we see the current leader of the task_scheduler election group is the instance above.\n","description":"","tags":null,"title":"Scheduled Tasks","uri":"/overview/scheduled-tasks/"},{"content":"We want to make it really easy to run handler services in Docker, toword that version 0.0.4 introduces a packager that can create containers on your behalf.\nPreparing Handlers Go Based The idea is that you would create a Handler per Go package, the packager will then pull in all the configured handlers into a small microservice.\npackage handler  import ( \taj \"github.com/choria-io/asyncjobs\" )  func AsyncJobHandler(ctx context.Context, log aj.Logger, task *aj.Task) (any, error) { \t// process your email } Place this in any package you like, for example git.example.com/example/email/new. You can have many handlers, as long as they are in packages like here.\nOther Languages Other languages are supported using NATS Request-Reply, implement them according to the protocol describe in Remote Request-Reply Handlers.\nPackaging In a empty directory create a file asyncjobs.yaml with the following content:\n# The NATS Context to connect with.## Same as NatsContext() client optionnats:AJ_EMAIL# The Work Queue to consume.## Same as BindWorkQueue() client optionqueue:EMAIL# The package name to generatename:git.example.com/example# The version of github.com/choria-io/asyncjobs to use,# something go get would accept. Defeaults to the same# as the CLI versionasyncjobs:latest# Use the RetryLinearTenMinutes retry policy,## Equivalent to client RetryBackoffPolicyName() optionretry:10m# Discard tasks that reach complete state.## Same as DiscardTaskStates() client optiondiscard:- completed# List of Task handlerstasks:- type:email:newpackage:git.example.com/example/email/newversion:v0.2.0- type:audit:logremote:true- type:webhook:callcommand:webhook/call.shWe set up a remote: true Task handler for audit:log Tasks, this will delegate to external processes, see Remote Request Reply Handlers.\nThe webhook:call Task handler is a shell script that should exist in commands/webhook/call.sh, it will be copied into the container. It’s most likely you will need dependencies not in the default container, I suggest using the generated one as a FROM container to derive one with your dependencies met via the alpine package system.\nNext we create our package:\n$ ajc package docker ╭────────────────────────────────────────────────────────────────╮ │ Handler Microservice Settings │ ├────────────────────────────────┬───────────────────────────────┤ │ Package Name │ git.example.com/example │ │ NATS Context Name │ AJ_EMAIL │ │ Work Queue │ EMAIL │ │ Task Handlers │ 2 │ │ github.com/choria-io/asyncjobs │ latest │ ╰────────────────────────────────┴───────────────────────────────╯ ╭───────────────────────────────────────────────────────────────────────────────────────────────╮ │ Handler Configuration and Packages │ ├──────────────┬───────────────────────┬────────────────────────────────────────────────────────┤ │ Task Type │ Handler Kind │ Detail │ ├──────────────┼───────────────────────┼────────────────────────────────────────────────────────┤ │ email:new │ Go Package │ git.example.com/example/email/new@v0.2.0 │ │ webhook:call │ External Command │ webhook/call.sh │ │ audit:log │ Request-Reply Service │ CHORIA_AJ.H.T.audit:log │ ╰──────────────┴───────────────────────┴────────────────────────────────────────────────────────╯ Build your container using 'docker build' $ ls -l total 12 -rw-rw-r-- 1 rip rip 166 Feb 8 17:48 asyncjobs.yaml -rw-r--r-- 1 rip rip 713 Feb 8 20:01 Dockerfile -rw-r--r-- 1 rip rip 2540 Feb 8 20:01 main.go drwxrwxr-x 3 rip rip 19 Feb 8 17:48 commands You see we have a main.go that will be built into a container:\n$ docker build . --tag example/email:latest $ docker push example/email:latest Running The container will rely on a NATS Context for connectivity options, lets create one in the same directory:\n$ pwd /home/myname/work/email_service $ XDG_CONFIG_HOME=`pwd` nats context add AJ_EMAIL --server nats://nats.example.net:4222 NATS Configuration Context \"AJ_EMAIL\" Server URLs: nats.example.net:4222 Path: /home/myname/work/email_service/nats/context/AJ_EMAIL.json We can now run it:\n$ docker run -ti -v \"/home/myname/work/email_service/nats:/handler/config/nats\" -p 8080:8080 --rm example/email:latest INFO[19:07:39] Connecting using Context AJ_EMAIL consuming work queue EMAIL with concurrency 4 WARN[19:07:39] Exposing Prometheus metrics on port 8080 Note we mount the nats configuration directory into /handler/config/nats which is where the container will look for the context configuration. Should you need other supporting files like credentials you can place them in the container and reference them at their in-container paths.\nEnvironment Configuration A few environment variables can be set to influence the container:\n   Variable Description YAML Item     AJ_WORK_QUEUE The name of the Queue to connect to queue   AJ_NATS_CONTEXT The NATS context to use for connectivity nats   XDG_CONFIG_HOME The prefix for NATS Context configuration, defaults to /handler/config    AJ_CONCURRENCY The number of workers to run, defaults to runtime.NumCPU()    AJ_DEBUG Set to 1 to enable debug logging    AJ_RETRY_POLICY Sets the Retry Backoff Policy, one of 10m, 1h, 1m, default retry    ","description":"","tags":null,"title":"Handlers in Docker","uri":"/overview/handlers-docker/"},{"content":"Typically, and for best performance, you implement your handlers in Go and compile them into the binary.\nIn order to support other programming languages we also support calling out over NATS in a Request-Reply fashion to a service that can be programmed in any language.\nIt’s worth understanding Routing, Handlers, Concurrency and Retry for background, these remote callout Handlers map exactly onto that model.\nRegistering with the Router client, _ := asyncjobs.NewClient(asyncjobs.NatsConn(nc), asyncjobs.BindWorkQueue(\"EMAIL\"))  router := asyncjobs.NewTaskRouter() router.RequestReply(\"email:new\", client)  client.Run(router) Here we register with the Router for tasks of type email:new that will call out via Request-Reply.\nIf all your Handlers are of this type I strongly suggest investigating our Docker Based Runner that can achieve this without writing any Go code.\nProtocol We implement a light-weight JSON + Headers protocol to communicate with remote services. They support returning errors including the ErrTerminateTask behavior.\nYour service must listen on CHORIA_AJ.H.T.email:new - most probably in a queue group - where you would replace email:new with whatever you chose as a task type. A handler that is registered with task type \"\" will handle all tasks of all types and the handling service should listen on CHORIA.AJ.H.T.catchall.\nTasks A request for a Task Handler will have these headers:\n   Header Value     AJ-Content-Type application/x-asyncjobs-task+json   AJ-Handler-Deadline 2009-11-10T23:00:00Z    The content-type is same for all Tasks, the Deadline is a UTC timestamp indicating by what time the remote service has to complete handling the task to avoid timeouts.\nThe body is simply a JSON format Task.\nResponses from your service can have these headers:\n   Header Description     AJ-Error Indicates an error was encountered, the value is set as task error, the task is retried later   AJ-Terminate Terminates the task via ErrTerminateTask, the value will be set as additional text in the error. No further retries are done    The body of your response is taken and stored with the Task unmodified.\nDemonstration To see this in action, we can use the nats CLI tool.\n$ nats reply CHORIA_AJ.H.T.email:new 'success' --context AJC 18:33:32 [#1] Received on subject \"CHORIA_AJ.H.T.email:new\": 18:33:33 AJ-Content-Type: application/x-asyncjobs-task+json 18:33:33 AJ-Handler-Deadline: 2022-02-09T17:34:31Z {\"id\":\"24smZHaWnjuP371iglxeQWK7nOi\",\"type\":\"email:new\",\"queue\":\"DEFAULT\",\"payload\":\"InsuLi4ufSI=\",\"state\":\"active\",\"created\":\"2022-02-09T17:28:41.943198067Z\",\"tried\":\"2022-02-09T17:33:33.005041134Z\",\"tries\":5} The CLI received the jobs with the 2 headers set and appropriate payload, it responsed with success and the task was completed.\n$ ajc task view 24smZHaWnjuP371iglxeQWK7nOi --json { \"id\": \"24smZHaWnjuP371iglxeQWK7nOi\", \"type\": \"email:new\", \"queue\": \"DEFAULT\", \"payload\": \"InsuLi4ufSI=\", \"result\": { \"payload\": \"dGVzdA==\", \"completed\": \"2022-02-09T17:33:33.00755251Z\" }, \"state\": \"complete\", \"created\": \"2022-02-09T17:28:41.943198067Z\", \"tried\": \"2022-02-09T17:33:33.007552104Z\", \"tries\": 5 } ","description":"","tags":null,"title":"Request-Reply Handlers","uri":"/reference/request-reply/"},{"content":"We publish Helm charts to deploy the system to Kubernetes.\nRequirements NATS Server with JetStream You need a NATS JetStream server, if you are a Choria User you can enable Choria Streams otherwise the NATS Community has their own NATS Helm Charts.\nConnection Context We use NATS Contexts to configure the connection between asyncjobs and NATS. If you already have a context configured using the NATS CLI then use nats context show CONTEXTNAME --json to get the keys and values to configure.\nFor me I needed some TLS Certificates to authenticate to NATS along with the context, so we made a secret called task-scheduler-tls holding that, you can put NATS credential files and more in the same manner:\n$ find asyncjobs/task-scheduler asyncjobs/task-scheduler/secret asyncjobs/task-scheduler/secret/tls.crt asyncjobs/task-scheduler/secret/tls.key asyncjobs/task-scheduler/secret/ca.crt $ kubectl -n asyncjobs create secret generic task-scheduler-tls --from-file asyncjobs/task-scheduler/secret Choria Helm Repository Choria has it’s own Helm repository that you need to import:\n$ helm repo add choria https://choria-io.github.io/helm $ helm repo update Kubernetes Namespace We suggest running the asyncjobs components in a namespace:\n$ kubectl create namespace asyncjobs namespace/asyncjobs created Task Scheduler Here I show a basic values file for the Task Scheduler, it will run 2 replicas with one being active:\n# asyncjobs-task-scheduler-values.yamlimage:tag:0.0.6taskScheduler:contextSecret:task-scheduler-tlscontext:url:nats://broker-broker-ss:4222ca:/etc/asyncjobs/secret/ca.crtkey:/etc/asyncjobs/secret/tls.keycert:/etc/asyncjobs/secret/tls.crtWe reference the secret added earlier.\n$ helm install --namespace asyncjobs --values asyncjobs-task-scheduler-values.yaml task-scheduler choria/asyncjobs-task-scheduler ","description":"","tags":null,"title":"Handlers in K8s","uri":"/overview/handlers-k8s/"},{"content":"Lifecycle events are small JSON messages that are published to notify about various stages of processing and the life of a client.\nToday the only event we support is one notifying about changes in Task State but more will be added. In future we will support emitting Cloud Event standard events.\nEvents are not guaranteed to be delivered and are not persisted, they are informational. While you can use them to build a kind of coupled system of waiting for a task to complete you should not rely on these events to be delivered in 100% of cases.\nEvent Types Each event has a type like io.choria.asyncjobs.v1.task_state aka asyncjobs.TaskStateChangeEventType that can help with parsing and routing of events through other systems.\nParsing an event We provide a helper to parse any supported event and to process them using the common go type switch pattern.\n// subscribe to all events sub, err := nc.SubscribeSync(asyncjobs.EventsSubjectWildcard) panicIfErr(err)  for { \tmsg, _ := sub.NextMsg(time.Minute) \tevent, kind, _ := asyncjobs.ParseEventJSON(msg.Data)  \tswitch e := event.(type) { \tcase asyncjobs.TaskStateChangeEvent: \t// handle task state change event  \tdefault: \t// logs the io.choria.asyncjobs.v1.task_state style task type \tlog.Printf(\"Unknown event type %s\", kind) \t} } TaskStateChangeEvent This event type is published for any state change of a Task, using it you can watch a task by ID or all tasks.\nThese events are published to CHORIA_AJ.E.task_state.* with the last token being the Job ID.\nOn the wire the messages look like here, with task_age being a go Duration.\n{  \"event_id\": \"24mHmiRY9eQCVU4xuHwsztJ2MJH\",  \"type\": \"io.choria.asyncjobs.v1.task_state\",  \"timestamp\": \"2022-02-07T10:16:42Z\",  \"task_id\": \"24mHmkobHqLE6bxiWPTwuV30xrO\",  \"state\": \"complete\",  \"tries\": 1,  \"queue\": \"DEFAULT\",  \"task_type\": \"email:new\",  \"task_age\": 4037478 } ","description":"","tags":null,"title":"Lifecycle Events","uri":"/reference/lifecycle-events/"},{"content":"This feature list is incomplete, at present the focus is on determining what will work well for the particular patterns JetStream enables, so there might be some churn in the feature set here.\nTasks  Task definitions stored post-processing, with various retention and discard policies Ability to retry a Task that has already been completed or failed Task deduplication Deadline per task - after this time the task will not be processed Tasks can depend on other tasks Max tries per task, capped to the queue tries Task state tracked throughout it’s lifecycle K-Sortable Task GUIDs Lifecycle events published about changes to task states  See Task Lifecycle for full background and details\nQueues  Queues can store different types of task Queues with caps on queued items and different queue-full behaviors Default or user supplied queue definitions Queue per client, many clients per queue  Processing  Retries of failed tasks with backoff schedules configurable using RetryBackoffPolicy(). Handler opt-in early termination. Parallel processing of tasks, horizontally or vertically scaled. Run time adjustable upper boundary on a per-queue basis Worker crashes does not impact the work queue Handler interface with task router to select appropriate handler by task type with wildcard matches Support for Handlers in all NATS Supported languages using Remote Handlers Statistics via Prometheus  Storage  Replicated storage using RAFT protocol within JetStream Streams, disk based or memory based KV for configuration and schedule storage KV for leader elections  Scheduled Tasks  Cron like schedules creating tasks on demand HA capable Scheduler process integrated with ajc Prometheus monitoring CLI CRUD operations via ajc task cron  See Scheduled Tasks\nMisc  Supports NATS Contexts for connection configuration Supports custom loggers, defaulting to go internal log  Command Line  Various info and state requests Configure aspects of Task and Queue storage Watch task processing Process tasks via shell commands CRUD on Tasks store or individual Task CRUD on Scheduled Tasks  Planned Features A number of features are planned in the near term, see our GitHub Issues\n","description":"","tags":null,"title":"Feature List","uri":"/overview/features/"},{"content":"Sometimes you want to run a handler in a insecure location and want to be sure it only executes tasks from trusted creators.\nTasks can be signed using ed25519 private keys and clients can be configured to only accept tasks created and signed using a specific key. We support requiring all tasks are signed when keys are configured (the default), or accepting unsigned tasks but requiring signed tasks are verified.\nFirst we need to create some keys, these should be saved to a file encoded using hex.Encode().\npubk, prik, err = ed25519.GenerateKey(nil) panicIfErr(err) Then we can configure the client:\nclient, err := asyncjobs.NewClient(  asyncjobs.NatsContext(\"AJC\"), \t // when tasks are created sign using this ed25519.PrivateKey, see also TaskSigningSeedFile()  asyncjobs.TaskSigningKey(prik),   // when loading tasks verify using this ed25519.PublicKey, see also TaskVerificationKeyFile()  asyncjobs.TaskVerificationKey(pubk),   // support loading unsigned tasks when a verification method is set, disabled by default  asyncjobs.TaskSignaturesOptional(), ) panicIfErr(err) On the command line the ajc tasks command has --sign and --verify flags which can either be hex encoded keys or paths to files holding them in hex encoded format.\nDocker containers built using ajc package docker can set a key in the environment variable AJ_VERIFICATION_KEY and can opt into optional signatures at build time by setting task_signatures_optional: true in the asyncjobs.yaml.\n","description":"","tags":null,"title":"Security","uri":"/reference/security/"},{"content":"Several terms are used in this system as outlined here.\nJetStream The underlying storage and work queue manager. See the NATS project documentation for background.\nWork Queue A Work Queue is JetStream Stream set with WorkQueue Retention policy. The underlying Stream holding these queues are called CHORIA_AJ_Q_DEFAULT for the DEFAULT queue.\nWork Item Work Items are placed in the Work Queue and scheduled by JetStream. The contents of the Work Queue are ProcessItem messages encoded in JSON format.\nClient Connects to JetStream and manages the enqueueing and routing of tasks.\nHandler Handlers are functions that can process a task with the signature func(context.Context, *asyncjobs.Task) (any, error).\nRouter The Router locates handlers for a particular task using the Type field as a matcher.\nSee Routing, Handlers, Concurrency and Retry.\nTask A task is a specific kind of Work Item that is handled by a Handler via a Router, this is the main processible unit. In time we anticipate other kinds of Item for example Scheduled items, now the only kind of Item is a Task.\nTask have time stamps, statuses and more. See Task Lifecycle.\nLifecycle Event Events are small messages published to notify listeners about the state of changes. Today only Task State changes are reported, in future we will report more such as Processor start and stop etc.\nSee Lifecycle Events\nScheduled Task A cron like schedule for creating tasks on demand. Requires the running of a Task Scheduler process. See Scheduled Tasks\n","description":"","tags":null,"title":"Terminology","uri":"/reference/terminology/"},{"content":"","description":"","tags":null,"title":"Categories","uri":"/categories/"},{"content":"","description":"","tags":null,"title":"Overviews","uri":"/overview/"},{"content":"","description":"","tags":null,"title":"References","uri":"/reference/"},{"content":"","description":"","tags":null,"title":"Tags","uri":"/tags/"}]